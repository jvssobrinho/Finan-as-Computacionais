# -*- coding: utf-8 -*-
"""Enseble learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yzYB5aK9mDPkIfF3hUIJMXr7OMmvUrT4
"""

!pip install simulate

pip install numpy pandas yfinance scikit-learn xgboost matplotlib

!pip install scikit-learn
!pip install stacking-regressor

pip install simpy

import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt

# Modelos de Ensemble Learning
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier
from xgboost import XGBClassifier

# Métricas e separação de dados
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import warnings
warnings.filterwarnings('ignore')
from sklearn.metrics import confusion_matrix
import seaborn as sns

def calcular_sharpe_ratio(retornos, periodos_por_ano=252):
    """Calcula o Sharpe Ratio anualizado a partir de uma série de retornos diários."""
    retorno_medio = retornos.mean()
    desvio_padrao = retornos.std()

    if desvio_padrao == 0:
        return 0

    sharpe_ratio = (retorno_medio / desvio_padrao) * np.sqrt(periodos_por_ano)
    return sharpe_ratio




def executar_backtest(modelo, X_train, y_train, X_test, y_test, df_teste):
    """
    Treina o modelo, executa a estratégia, calcula o Sharpe Ratio,
    imprime a Acurácia e plota a Matriz de Confusão.
    """
    # Treinar o modelo
    modelo.fit(X_train, y_train)

    # Fazer previsões no conjunto de teste
    previsoes = modelo.predict(X_test)

    # Criar um DataFrame com os resultados do teste
    backtest_df = df_teste.copy()
    backtest_df['previsao'] = previsoes

    # Calcular retornos
    backtest_df['retorno_ativo'] = backtest_df['Close'].pct_change()
    backtest_df['retorno_estrategia'] = backtest_df['retorno_ativo'] * backtest_df['previsao']
    backtest_df['retorno_cum_ativo'] = (1 + backtest_df['retorno_ativo']).cumprod() - 1
    backtest_df['retorno_cum_estrategia'] = (1 + backtest_df['retorno_estrategia']).cumprod() - 1

    # Calcular métricas de performance
    sharpe = calcular_sharpe_ratio(backtest_df['retorno_estrategia'])
    retorno_total_estrategia = backtest_df['retorno_cum_estrategia'].iloc[-1]

    print("--- Resultados do Backtest ---")
    print(f"Sharpe Ratio Anualizado: {sharpe:.4f}")
    print(f"Retorno Total da Estratégia: {retorno_total_estrategia:.2%}")

    # =========================================================================
    # == CERTIFIQUE-SE QUE A LINHA ABAIXO ESTÁ PRESENTE E CORRETA NO SEU CÓDIGO ==
    print(f"Acurácia do Modelo no Teste: {accuracy_score(y_test, previsoes):.2%}")
    # =========================================================================

    # Plotar resultados financeiros
    plt.figure(figsize=(14, 7))
    plt.plot(backtest_df['retorno_cum_estrategia'], label='Retorno da Estratégia')
    plt.plot(backtest_df['retorno_cum_ativo'], label='Retorno do Ativo (Buy & Hold)', linestyle='--')
    plt.title(f'Resultado do Backtest com {modelo.__class__.__name__}')
    plt.ylabel('Retorno Cumulativo')
    plt.xlabel('Data')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Cálculo e plotagem da Matriz de Confusão
    cm = confusion_matrix(y_test, previsoes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Previsto: Não Sobe (0)', 'Previsto: Sobe (1)'],
                yticklabels=['Real: Não Sobe (0)', 'Real: Sobe (1)'])
    plt.title(f'Matriz de Confusão - {modelo.__class__.__name__}')
    plt.ylabel('Valor Real')
    plt.xlabel('Valor Previsto')
    plt.show()

    return sharpe

ativo = 'PETR4.SA'
ticker = yf.Ticker(ativo)

# Baixar todo o histórico disponível do ativo
df = ticker.history(period='max', auto_adjust=True)

print("Primeiros dias:")
print(df.head())
print("\nÚltimos dias:")
print(df.tail())

#Criação de Indicadores:

#Indicador1 : retorno diário:

for i in range(1, 6):
    df[f'retorno_d{i}'] = df['Close'].pct_change(periods=i).shift(1)

# Indicador 2: Relative Strength Index (RSI)
delta = df['Close'].diff()
ganho = (delta.where(delta > 0, 0)).rolling(window=14).mean()
perda = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
rs = ganho / perda
df['rsi'] = 100 - (100 / (1 + rs))

# Indicador 3: Moving Average Convergence Divergence (MACD)
ema_12 = df['Close'].ewm(span=12, adjust=False).mean()
ema_26 = df['Close'].ewm(span=26, adjust=False).mean()
df['macd'] = ema_12 - ema_26
df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()

# Indicador 4: Bollinger Bands
rolling_mean_20 = df['Close'].rolling(window=20).mean()
rolling_std_20 = df['Close'].rolling(window=20).std()
df['bollinger_upper'] = rolling_mean_20 + (rolling_std_20 * 2)
df['bollinger_lower'] = rolling_mean_20 - (rolling_std_20 * 2)
df['dist_bollinger_upper'] = df['Close'] - df['bollinger_upper']
df['dist_bollinger_lower'] = df['Close'] - df['bollinger_lower']

#DEFINIÇÃO DA VARIÁVEL ALVO
horizonte_predicao = 5 # Prever se o preço sobe ou desce em 5 dias
df['retorno_futuro'] = df['Close'].pct_change(periods=horizonte_predicao).shift(-horizonte_predicao)

# Alvo: 1 se o retorno futuro for positivo, 0 caso contrário
df['alvo'] = (df['retorno_futuro'] > 0).astype(int)

# Remover linhas com NaN (gerados pelos indicadores e shifts)
df.dropna(inplace=True)

print(f"\nFeatures criadas. Dimensão do DataFrame final: {df.shape}")
print(f"Distribuição do Alvo: \n{df['alvo'].value_counts(normalize=True)}")

#PREPARAÇÃO DOS DADOS E FUNÇÕES DE BACKTEST
features = [
    'retorno_d1', 'retorno_d2', 'retorno_d3', 'retorno_d4', 'retorno_d5',
    'rsi', 'macd', 'macd_signal', 'dist_bollinger_upper', 'dist_bollinger_lower'
]

X = df[features]
y = df['alvo']

# Usaremos 80% dos dados para treinar e 20% para testar
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
print(f"\nDados separados: {len(X_train)} para treino, {len(X_test)} para teste.")
# DataFrame correspondente ao período de teste para o backtest
df_teste = df.iloc[-len(X_test):]

# Dicionário para armazenar os resultados
resultados = {}

#APLICAÇÃO DOS MODELOS DE ENSEMBLE LEARNING
# --- Modelo 1: Random Forest ---
print("\n--- [1/4] Executando Random Forest Classifier ---")
# Parâmetros ajustados: mais árvores (n_estimators), profundidade máxima para evitar overfitting,
# e min_samples_leaf para garantir que cada "folha" da árvore tenha um número mínimo de amostras.
rf_model = RandomForestClassifier(
    n_estimators=200,          # Aumentamos o número de árvores
    max_depth=10,              # Limitamos a profundidade
    min_samples_leaf=15,       # Exigimos mais amostras por folha
    random_state=42,
    n_jobs=-1                  # Usar todos os processadores
)
resultados['Random Forest'] = executar_backtest(rf_model, X_train, y_train, X_test, y_test, df_teste)

# --- Modelo 2: XGBoost ---
print("\n--- [2/4] Executando XGBoost Classifier ---")
# Parâmetros ajustados: learning_rate menor para um aprendizado mais cauteloso,
# mais estimadores e controle de complexidade (max_depth, gamma).
xgb_model = XGBClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=5,
    gamma=0.1,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
resultados['XGBoost'] = executar_backtest(xgb_model, X_train, y_train, X_test, y_test, df_teste)

# --- Modelo 3: AdaBoost ---
print("\n--- [3/4] Executando AdaBoost Classifier ---")
# Parâmetros ajustados: um número razoável de estimadores e um learning_rate
# para controlar a contribuição de cada um.
ada_model = AdaBoostClassifier(
    n_estimators=100,
    learning_rate=0.1,
    random_state=42
)
resultados['AdaBoost'] = executar_backtest(ada_model, X_train, y_train, X_test, y_test, df_teste)

# --- Modelo 4: Voting Classifier (Meta-Ensemble) ---
print("\n--- [4/4] Executando Voting Classifier ---")
clf1 = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=15, random_state=42, n_jobs=-1)
clf2 = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=5, gamma=0.1, use_label_encoder=False, eval_metric='logloss', random_state=42)
clf3 = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42)

voting_model = VotingClassifier(
    estimators=[('rf', clf1), ('xgb', clf2), ('ada', clf3)],
    voting='soft' # 'soft' usa a média das probabilidades previstas, 'hard' usa o voto da maioria.
)
resultados['Voting Classifier'] = executar_backtest(voting_model, X_train, y_train, X_test, y_test, df_teste)

#ANÁLISE FINAL DOS RESULTADOS
print("\n\n--- Resumo Final dos Sharpe Ratios ---")
resultados_df = pd.DataFrame.from_dict(resultados, orient='index', columns=['Sharpe Ratio Anualizado'])
resultados_df['Atingiu a Meta (> 0.4)'] = resultados_df['Sharpe Ratio Anualizado'] > 0.4
print(resultados_df.sort_values(by='Sharpe Ratio Anualizado', ascending=False))



