# -*- coding: utf-8 -*-
"""Análise Estatística IBOVESPA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cSDGqEsbhzv-tredvmx9Hw6NVbgTyEvm

<a href="https://colab.research.google.com/github/codigoquant/python_para_investimentos/blob/master/07_AN%C3%81LISE_ESTAT%C3%8DSTICA_DA_QUEDA_DE_12_DO_IBOV_Python_para_Investimentos_com_Google_Colab.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# 1. Configurações Iniciais
"""

#!pip install yfinance --upgrade --no-cache-dir
import yfinance as yf

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns # usado juntamente com matplotlib para gráficos estatísticos
sns.set()

import matplotlib
matplotlib.rcParams['figure.figsize'] = (16,8)
matplotlib.rcParams.update({'font.size': 22})

import warnings
warnings.filterwarnings('ignore')

# computação científica, usa Numpy
from scipy.stats import norm,t,shapiro, kurtosis, skew, mannwhitneyu,kruskal,  friedmanchisquare
from numpy.random import seed,randn

# QQ Plot
from statsmodels.graphics.gofplots import qqplot
from matplotlib import pyplot

"""# 2. Análise Estatística do Índice Bovespa"""

petrobras = yf.download(["PETR3.SA","PETR4.SA"])[["Close"]]

petrobras







petrobras['retorno_PETR3'] = petrobras['Close']['PETR3.SA'].pct_change()
petrobras['retorno_PETR4'] = petrobras['Close']['PETR4.SA'].pct_change()

petrobras.dropna(inplace=True)

petrobras

# Limpa a figura atual para evitar sobreposição de gráficos anteriores
plt.clf()
# Cria um histograma da série ibov['retorno'], dividindo os dados em 100 intervalos (bins=100).
# O parâmetro kde=False desativa a curva de densidade estimada (KDE), mostrando apenas o histograma.sns.distplot(ibov['retorno'], bins=100, kde=False);
sns.distplot(petrobras['retorno_PETR4'], bins=100, kde=False);
plt.xlim(-0.2, 0.2)
print( 'excess kurtosis (formato da cauda) of normal distribution (should be 0): {}'.format( kurtosis(petrobras['retorno_PETR4']) ))
print( 'skewness(simetria, inclinação) of normal distribution (should be 0): {}'.format( skew(petrobras['retorno_PETR4']) ))

# Limpa a figura atual para evitar sobreposição de gráficos anteriores
plt.clf()
# Cria um histograma da série ibov['retorno'], dividindo os dados em 100 intervalos (bins=100).
# O parâmetro kde=False desativa a curva de densidade estimada (KDE), mostrando apenas o histograma.sns.distplot(ibov['retorno'], bins=100, kde=False);
sns.distplot(petrobras['retorno_PETR3'], bins=100, kde=False);
plt.xlim(-0.2, 0.2)
print( 'excess kurtosis (formato da cauda) of normal distribution (should be 0): {}'.format( kurtosis(petrobras['retorno_PETR3']) ))
print( 'skewness(simetria, inclinação) of normal distribution (should be 0): {}'.format( skew(petrobras['retorno_PETR3']) ))

plt.clf()
# Cria um histograma da série ibov['retorno'], dividindo os dados em 100 intervalos (bins=100).
# O parâmetro kde=False desativa a curva de densidade estimada (KDE), mostrando apenas o histograma.sns.distplot(ibov['retorno'], bins=100, kde=False);
sns.distplot(petrobras['retorno_PETR3'], bins=100, kde=True);
plt.xlim(-0.2, 0.2)

plt.clf()
# Cria um histograma da série ibov['retorno'], dividindo os dados em 100 intervalos (bins=100).
# O parâmetro kde=False desativa a curva de densidade estimada (KDE), mostrando apenas o histograma.sns.distplot(ibov['retorno'], bins=100, kde=False);
sns.distplot(petrobras['retorno_PETR4'], bins=100, kde=True);
plt.xlim(-0.2, 0.2)







# Plot settings following the specified scientific theme guidelines
fig, ax = plt.subplots(figsize=(9, 6))
plt.subplots_adjust(left=0.15, right=0.85, top=0.85, bottom=0.15)
ax.set_axisbelow(True)

# Plot histograms on the same axes
sns.histplot(petrobras['retorno_PETR4'], bins=100, kde=False, color="#766CDB", alpha=0.7, label="PETR4", ax=ax)
sns.histplot(petrobras['retorno_PETR3'], bins=100, kde=False, color="#DA847C", alpha=0.7, label="PETR3", ax=ax)

# Aesthetics
ax.set_xlim(-0.2, 0.2)
ax.set_xlabel("Retorno", labelpad=10, fontsize=16, fontweight="medium", color="#333333")
ax.set_ylabel("Frequency", labelpad=10, fontsize=16, fontweight="medium", color="#333333")
ax.set_title("Histogramas dos retornos: PETR4 vs. PETR3", pad=15, fontsize=20, fontweight="semibold", color="#222222")
ax.tick_params(axis='both', labelsize=14, colors="#555555")
ax.legend(fontsize=12, loc="upper right", frameon=False)

# Grid lines
ax.grid(True, which='both', linestyle='--', linewidth=0.5, color="#E0E0E0")

plt.show()

fig, ax = plt.subplots(figsize=(9, 6))
plt.subplots_adjust(left=0.15, right=0.85, top=0.85, bottom=0.15)
ax.set_axisbelow(True)

# Plot density-normalized histograms
sns.histplot(petrobras['retorno_PETR4'], bins=100, stat='density', kde=False,
             color="#766CDB", alpha=0.7, label="PETR4", ax=ax)
sns.histplot(petrobras['retorno_PETR3'], bins=100, stat='density', kde=False,
             color="#DA847C", alpha=0.7, label="PETR3", ax=ax)

# Styling
ax.set_xlim(-0.2, 0.2)
ax.set_xlabel("Retorno", labelpad=10, fontsize=16, fontweight="medium", color="#333333")
ax.set_ylabel("Densidade", labelpad=10, fontsize=16, fontweight="medium", color="#333333")
ax.set_title("Histogramas normalizados dos retornos: PETR4 vs. PETR3", pad=15, fontsize=20, fontweight="semibold", color="#222222")
ax.tick_params(axis='both', labelsize=14, colors="#555555")
ax.legend(fontsize=12, frameon=False)
ax.grid(True, which='both', linestyle='--', linewidth=0.5, color="#E0E0E0")

plt.show()

petrobras

media_PETR3 = petrobras['retorno_PETR3'].mean()
print('Retorno médio PETR3 = {:.2f}%'.format(media_PETR3*100))

media_PETR4 = petrobras['retorno_PETR4'].mean()
print('Retorno médio PETR4 = {:.2f}%'.format(media_PETR3*100))

desvio_padrao_petr3 = petrobras['retorno_PETR3'].std()
print('Desvio padrão petr3 = {:.2f}%'.format(desvio_padrao_petr3*100))

desvio_padrao_petr4 = petrobras['retorno_PETR4'].std()
print('Desvio padrão petr4 = {:.2f}%'.format(desvio_padrao_petr3*100))

"""## Cisnes Negros ##
* 1997-10-27 - Crise Financeira Asiática, que afetou os mercados globais. A crise começou na Tailândia, com a desvalorização da moeda local, e se espalhou para outros países asiáticos, como Malásia, Indonésia e Coreia do Sul.s

* 1998-09-10 - A Rússia enfrentava uma grave crise econômica, com a forte desvalorização do rublo e dificuldades para pagar sua dívida externa. O governo russo decretou moratória, ou seja, anunciou que não conseguiria honrar seus compromissos financeiros. Isso gerou pânico nos mercados globais, levando investidores a retirarem capital de países emergentes, incluindo o Brasil. Como reflexo, o Ibovespa despencou 15,83%, acionando o mecanismo de circuit breaker para interromper as negociações. Esse evento foi um dos momentos mais críticos da economia brasileira nos anos 90, levando o governo a elevar os juros para 49,75% na tentativa de conter a fuga de dólares.
"""

# dias em que petr3 teve retorno abaixo de 10%
petrobras[petrobras["retorno_PETR3"] < -0.10]



"""

Análise de Quedas da Ação PETR3
A tabela a seguir apresenta os dias em que a ação PETR3 (Petrobras ON) registrou quedas diárias superiores a 10%, com base nos dados fornecidos.


| Data       | Preço de Fechamento (R$) | Retorno Diário |
|:-----------|:-------------------------|:---------------|
| 2008-10-15 | 7.633456                 | -13.85%        |
| 2008-10-24 | 6.319949                 | -10.19%        |
| 2008-11-12 | 6.499773                 | -13.25%        |
| 2013-12-02 | 4.753724                 | -10.37%        |
| 2014-09-29 | 5.328393                 | -10.44%        |
| 2014-10-27 | 4.223689                 | -10.38%        |
| 2015-01-28 | 2.590649                 | -10.48%        |
| 2017-05-18 | 4.283727                 | -11.37%        |
| 2018-05-24 | 6.976404                 | -14.55%        |
| 2018-05-28 | 5.950992                 | -14.07%        |
| 2018-06-01 | 5.677350                 | -14.92%        |
| 2020-03-06 | 7.416532                 | -10.26%        |
| 2020-03-09 | 5.215616                 | -29.68%        |
| 2020-03-11 | 5.046079                 | -10.84%        |
| 2020-03-12 | 3.982610                 | -21.08%        |
| 2020-03-16 | 4.047343                 | -17.21%        |
| 2020-03-18 | 3.406179                 | -15.52%        |
| 2020-03-27 | 4.016517                 | -10.75%        |
| 2021-02-22 | 6.710631                 | -20.48%        |
| 2024-03-08 | 29.079346                | -10.37%        |"""

# dias em que petr3 teve retorno abaixo de 10%
petrobras[petrobras["retorno_PETR4"] < -0.10]

"""Análise de Quedas da Ação PETR4
A tabela a seguir detalha os dias em que a ação PETR4 (Petrobras PN) sofreu quedas diárias superiores a 10%. A análise é baseada na coluna retorno_PETR4, que mostra a variação percentual negativa do preço de fechamento do ativo.

| Data       | Preço de Fechamento (R$) | Retorno Diário |
|:-----------|:-------------------------|:---------------|
| 2000-04-17 | 1.153241                 | -11.02%        |
| 2008-10-15 | 5.776538                 | -12.09%        |
| 2008-10-24 | 4.910058                 | -10.13%        |
| 2008-10-27 | 4.358879                 | -11.23%        |
| 2008-11-12 | 4.963008                 | -13.76%        |
| 2011-08-17 | 5.412295                 | -11.19%        |
| 2014-09-29 | 5.429363                 | -11.17%        |
| 2014-10-27 | 4.238406                 | -12.64%        |
| 2014-12-15 | 2.644625                 | -11.09%        |
| 2015-01-28 | 2.659220                 | -10.16%        |
| 2016-03-15 | 1.929467                 | -10.68%        |
| 2017-05-18 | 3.838501                 | -15.76%        |
| 2018-05-24 | 5.873099                 | -13.71%        |
| 2018-05-28 | 4.945920                 | -14.60%        |
| 2018-06-01 | 4.726558                 | -14.86%        |
| 2020-02-26 | 8.246352                 | -10.05%        |
| 2020-03-09 | 5.049752                 | -29.70%        |
| 2020-03-12 | 3.964291                 | -20.50%        |
| 2020-03-16 | 4.118458                 | -15.00%        |
| 2020-03-18 | 3.552130                 | -13.15%        |
| 2021-02-22 | 6.818088                 | -20.71%        |

# Definição da Função Normal

A **Função de Densidade de Probabilidade (PDF)** da distribuição normal é dada por:

$$
F(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}
$$

Onde:
- \( x \) → Valor da variável aleatória
- \( \mu \) → Média da distribuição
- \( \sigma \) → Desvio padrão
- \( e \) → Base do logaritmo natural (~2.718)
- \( \pi \) → Constante matemática (~3.1416)

# Função de Distribuição Acumulada (CDF)

A **Função de Distribuição Acumulada (CDF)** calcula a probabilidade de uma variável aleatória assumir um valor menor ou igual a um determinado ponto. Para uma distribuição normal, o cálculo do CDF envolve a integral da **função de densidade de probabilidade (PDF)**.

## Fórmula da CDF para uma distribuição normal padrão

$$
F(x) = \frac{1}{2} \left[ 1 + \text{erf} \left(\frac{x - \mu}{\sigma \sqrt{2}}\right) \right]
$$
### Definições na Distribuição Normal

- $x$ é o valor para o qual queremos calcular a probabilidade acumulada;
- $\mu$ é a média da distribuição;
- $\sigma$ é o desvio padrão;
- $\text{erf}$ é a função erro matemática, usada para calcular probabilidades em distribuições normais.is.
"""

x = np.linspace(-0.3, 0.3, 100)  # Valores de retorno para o eixo X

# Calculando a CDF
# calcula a distribuição de probabilidade de uma variável aleatória normalmente distribuída (com média = media_PETR3 e desvio padrão = desvio_padrao_petr3)
cdf_values = norm.cdf(x, loc=media_PETR3, scale=desvio_padrao_petr3)

# Criando o gráfico
plt.figure(figsize=(8, 5))
plt.plot(x, cdf_values, label="CDF da distribuição normal para media_PETR3")
plt.axhline(y=norm.cdf(-0.12, loc=media_PETR3, scale=desvio_padrao_petr3), color='r', linestyle="--", label="Probabilidade de retorno <= -0.10: Ínfima")
plt.xlabel("Retorno da petr3")
plt.ylabel("Probabilidade acumulada")
plt.title("Função de Distribuição Acumulada para petr3 (CDF)")
plt.legend()
plt.grid()
plt.show()

x = np.linspace(-0.3, 0.3, 100)  # Valores de retorno para o eixo X

# Calculando a CDF
# calcula a distribuição de probabilidade de uma variável aleatória normalmente distribuída (com média = media_PETR4 e desvio padrão = desvio_padrao_petr4)
cdf_values = norm.cdf(x, loc=media_PETR4, scale=desvio_padrao_petr4)

# Criando o gráfico
plt.figure(figsize=(8, 5))
plt.plot(x, cdf_values, label="CDF da distribuição normal para media_PETR4")
plt.axhline(y=norm.cdf(-0.12, loc=media_PETR4, scale=desvio_padrao_petr4), color='r', linestyle="--", label="Probabilidade de retorno <= -0.10: Ínfima")
plt.xlabel("Retorno da petr3")
plt.ylabel("Probabilidade acumulada")
plt.title("Função de Distribuição Acumulada para petr4 (CDF)")
plt.legend()
plt.grid()
plt.show()

petrobras

# https://www.delftstack.com/pt/howto/matplotlib/plot-cdf-matplotlib-python/
petrobras['Cumulative Return PETR3'] = (1 + petrobras['retorno_PETR3']).cumprod()
petrobras['Cumulative Return PETR3'].plot(label='Curva',figsize=(16,8),title='Cumulative Return')

# https://www.delftstack.com/pt/howto/matplotlib/plot-cdf-matplotlib-python/
petrobras['Cumulative Return PETR4'] = (1 + petrobras['retorno_PETR4']).cumprod()
petrobras['Cumulative Return PETR4'].plot(label='Curva',figsize=(16,8),title='Cumulative Return')

petrobras['Close']['PETR3.SA'].plot(label='Curva',figsize=(16,8),title='Cotações')

petrobras['Close']['PETR4.SA'].plot(label='Curva',figsize=(16,8),title='Cotações')

plt.hist(petrobras['retorno_PETR3'], bins=100, density=True, cumulative=True, label="CDF", histtype="step")
plt.xlabel("X")
plt.ylabel("Probability")
#plt.xticks(np.arange(0, 10))
plt.title("CDF using Histogram Plot")
plt.xlim(-0.2, 0.2)
plt.show()

plt.hist(petrobras['retorno_PETR4'], bins=100, density=True, cumulative=True, label="CDF", histtype="step")
plt.xlabel("X")
plt.ylabel("Probability")
#plt.xticks(np.arange(0, 10))
plt.title("CDF using Histogram Plot")
plt.xlim(-0.2, 0.2)
plt.show()

"""**Qual a probabilidade do ibov cair mais que 10% considerando que os retornos seguem uma distribuição normal?**"""

# cumulative distribution function (CDF)
probabilidade_teorica = norm.cdf(-0.10, loc=media_PETR3, scale=desvio_padrao_petr3)
print('{:.8f}%'.format(probabilidade_teorica*100))

frequencia_teorica = 1 / probabilidade_teorica
print('Uma vez a cada {} dias'.format(int(round(frequencia_teorica, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_teorica/252, 5))))

petrobras['retorno_PETR3'].plot(title="Retorno Diário do Índice Bovespa");

# norm.rvs gera números randomicos dentro de uma distribuicao normal de acordo com os parametros
petrobras['retorno_teorico'] = norm.rvs(size=petrobras['retorno_PETR3'].size,  loc=media_PETR3, scale=desvio_padrao_petr3)
print( 'excess kurtosis (formato da cauda) of normal distribution (should be 0): {}'.format( kurtosis(petrobras['retorno_teorico']) ))
print( 'skewness(simetria, inclinação) of normal distribution (should be 0): {}'.format( skew(petrobras['retorno_teorico']) ))

ax = petrobras['retorno_teorico'].plot(title="Retorno Normal Simulado");
ax.set_ylim(-0.2, 0.4)

# ajuste com distribuição normal
sns.distplot(petrobras['retorno_teorico'], bins=100, kde=False, fit=norm);
plt.xlim(-0.2, 0.2)
# não se ajusta perfeitamente

# cumulative distribution function (CDF)
probabilidade_teorica = norm.cdf(-0.10, loc=media_PETR4, scale=desvio_padrao_petr4)
print('{:.8f}%'.format(probabilidade_teorica*100))
frequencia_teorica = 1 / probabilidade_teorica
print('Uma vez a cada {} dias'.format(int(round(frequencia_teorica, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_teorica/252, 5))))
petrobras['retorno_PETR4'].plot(title="Retorno Diário do Índice Bovespa");
# norm.rvs gera números randomicos dentro de uma distribuicao normal de acordo com os parametros

petrobras['retorno_teorico'] = norm.rvs(size=petrobras['retorno_PETR4'].size,  loc=media_PETR4, scale=desvio_padrao_petr4)
print( 'excess kurtosis (formato da cauda) of normal distribution (should be 0): {}'.format( kurtosis(petrobras['retorno_teorico']) ))
print( 'skewness(simetria, inclinação) of normal distribution (should be 0): {}'.format( skew(petrobras['retorno_teorico']) ))

ax = petrobras['retorno_teorico'].plot(title="Retorno Normal Simulado");
ax.set_ylim(-0.2, 0.4)

# ajuste com distribuição normal
sns.distplot(petrobras['retorno_teorico'], bins=100, kde=False, fit=norm);
plt.xlim(-0.2, 0.2)
# não se ajusta perfeitamente

"""### Ajuste com a Distribuição t-Student

O ajuste com a **distribuição t-Student** é feito porque essa distribuição é mais apropriada para modelar retornos financeiros, especialmente quando há **caudas longas**. Isso significa que a distribuição considera **eventos extremos** (valores muito altos ou baixos) com maior probabilidade do que a distribuição normal. Mais realista.
"""

# ajuste com distribuição t-student. Distribuição de cauda longa.
sns.distplot(petrobras['retorno_PETR3'], bins=100, kde=False, fit=t);
plt.xlim(-0.2, 0.2)

"""### Ajuste da Distribuição t-Student

- O método `fit()` ajusta a **distribuição t-Student** aos dados históricos dos retornos do IBOV.
- Ele retorna três parâmetros principais:
  - **Graus de liberdade (`df`)** → Indica a dispersão das caudas (quanto menor, maior a concentração).
  - **Média (`loc`)** → Representa o centro da distribuição dos retornos.
  - **Desvio padrão (`scale`)** → Mede a variabilidade dos retornos em torno da média.
"""

# parâmetros da t-student utilizada
(graus_de_liberdade3,  media_t3, desvio_padrao_t3) = t.fit(petrobras['retorno_PETR3'])
(graus_de_liberdade4,  media_t4, desvio_padrao_t4) = t.fit(petrobras['retorno_PETR4'])
print('Distribuição T-Student\nGraus de liberdade={:.2f} \nMédia={:.4f} \nDesvio padrão={:.5f}'.format(graus_de_liberdade3, media_t3, desvio_padrao_t3))
print('Distribuição T-Student\nGraus de liberdade={:.2f} \nMédia={:.4f} \nDesvio padrão={:.5f}'.format(graus_de_liberdade4, media_t4, desvio_padrao_t4))

probabilidade_teorica_t3 = t.cdf(-0.10, graus_de_liberdade3,  loc=media_t3, scale=desvio_padrao_t3)
print('{:.8f}%'.format(probabilidade_teorica_t3*100))
probabilidade_teorica_t4 = t.cdf(-0.10, graus_de_liberdade4,  loc=media_t4, scale=desvio_padrao_t4)
print('{:.8f}%'.format(probabilidade_teorica_t4*100))

frequencia_teorica_t3 = 1 / probabilidade_teorica_t3
print('Para uma distribuição T-Student: \nUma vez a cada {} dias'.format(int(round(frequencia_teorica_t3, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_teorica_t3/252, 5))))
frequencia_teorica_t4 = 1 / probabilidade_teorica_t4
print('Para uma distribuição T-Student: \nUma vez a cada {} dias'.format(int(round(frequencia_teorica_t4, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_teorica_t4/252, 5))))

frequencia_teorica = 1 / probabilidade_teorica
print('Para uma distribuição Normal: \nUma vez a cada {} dias'.format(int(round(frequencia_teorica, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_teorica/252, 5))))

# total de dias dividido pela quantidade de dias. Resultado é a frequencia
frequencia_observada = petrobras['retorno_PETR3'].size / petrobras[petrobras['retorno_PETR3'] < -0.10].shape[0]
print('Na vida real aconteceu: \nUma vez a cada {} dias'.format(int(round(frequencia_observada, 5))))
print('Ou uma vez a cada {} anos'.format(int(round(frequencia_observada/252, 5))))

"""## Testes de Normalidade

### Teste de Shapiro-Wilk

O **teste de Shapiro-Wilk** é indicado para avaliar se um conjunto de dados segue uma **distribuição normal**. Ele é particularmente útil para **amostras pequenas** (tipicamente abaixo de 50 observações), mas pode ser aplicado a conjuntos maiores também.

### Características do teste de Shapiro-Wilk:
- **Hipótese nula** (\(H_0\)) → Os dados vêm de uma distribuição normal/Gaussiana.
- **Hipótese alternativa** (\(H_A\)) → Os dados não seguem uma distribuição normal.
- Se o **valor-p** for **menor que 0.05** → Rejeitamos \(H_0\) e concluímos que os dados **não** seguem uma distribuição normal.
- Se o **valor-p** for **maior que 0.05** → Não há evidências suficientes para rejeitar \(H_0\), então os dados **podem ser considerados normais**.
"""

petrobras

tickers = pd.read_excel("IBOVDia_02-06-25.xlsx")
tickers

tickers = tickers['Ticker'].unique().tolist()

tickers_com_suffix = [ticker + '.SA' for ticker in tickers]

tickers = yf.download(tickers_com_suffix)[["Close"]]
tickers

returns = tickers.pct_change()

returns

returns = returns.dropna()

returns





normality_results = []

# Define the significance level
alpha = 0.05

print("Starting normality tests for each asset...")
print("-" * 50)

# Loop through each column (asset) in the returns DataFrame
for ticker in returns.columns:
    print(f"\n--- Testing: {ticker} ---")
    x = returns[ticker].dropna() # Drop NaNs for the current asset's series

    # Check if there's enough data after dropping NaNs for Shapiro test (min 3 samples)
    if len(x) < 3:
        print(f"  Not enough data points for Shapiro-Wilk test for {ticker}. Skipping.")
        result = {
            'Ticker': ticker,
            'Shapiro_Statistics': np.nan,
            'Shapiro_p_value': np.nan,
            'Normal_Hypothesis': 'Not enough data',
            'Excess_Kurtosis': np.nan,
            'Skewness': np.nan
        }
    else:
        # Shapiro-Wilk Test
        stat, p = shapiro(x)
        print(f'  Shapiro Statistics={stat:.3f}, p={p:.3f}')

        normal_hypothesis = 'Sample looks Gaussian (fail to reject H0)' if p > alpha else 'Sample does not look Gaussian (reject H0)'
        print(f'  {normal_hypothesis}')

        # Kurtosis and Skewness
        exc_kurt = kurtosis(x)
        sk = skew(x)
        print(f'  Excess Kurtosis (should be 0 for normal): {exc_kurt:.4f}')
        print(f'  Skewness (should be 0 for normal): {sk:.4f}')

        # Store results
        result = {
            'Ticker': ticker,
            'Shapiro_Statistics': stat,
            'Shapiro_p_value': p,
            'Normal_Hypothesis': normal_hypothesis,
            'Excess_Kurtosis': exc_kurt,
            'Skewness': sk
        }
    normality_results.append(result)
    print("-" * 50)

# Convert the list of results into a DataFrame for easier viewing
results_df = pd.DataFrame(normality_results)

print("\n--- Summary of Normality Test Results ---")
print(results_df)



gaussian_assets_df = results_df[results_df['Normal_Hypothesis'] == 'Sample looks Gaussian (fail to reject H0)']
not_gaussian_assets_df = results_df[results_df['Normal_Hypothesis'] == 'Sample does not look Gaussian (reject H0)']
print("Assets with returns that look Gaussian (Fail to Reject H0):")
print(gaussian_assets_df)

not_gaussian_assets_df = results_df[results_df['Normal_Hypothesis'] == 'Sample does not look Gaussian (reject H0)']
print("Assets with returns that look Gaussian (Fail to Reject H0):")
print(not_gaussian_assets_df)





returns

not_gaussian_assets_df

returns

returns[('Close', 'MOTV3.SA')].dropna()

"""### Q-Q Plot - Teste visual de normalidade"""

import statsmodels.api as sm
import matplotlib.pyplot as plt
import pandas as pd # Se você estiver usando pandas para o seu DataFrame 'returns'
# q-q plot
qqplot(returns[('Close', 'MOTV3.SA')].dropna(),line='s')
plt.show()







# q-q plot
qqplot(returns[('Close', 'WEGE3.SA')].dropna(), line='s')
plt.show()





import scipy.stats as stats

# Ordenando os retornos
dados_ordenados = np.sort(returns[('Close', 'MOTV3.SA')].dropna())

# Obtendo quantis teóricos da distribuição normal
quantis_teoricos = stats.norm.ppf((np.arange(1, len(dados_ordenados) + 1) - 0.5) / len(dados_ordenados))

# Calculando a correlação de Pearson entre os quantis observados e os teóricos
correlacao, _ = stats.pearsonr(dados_ordenados, quantis_teoricos)

print(f"Correlação dos quantis para o MOTV3: {correlacao:.4f}")

# Ordenando os retornos
dados_ordenados = np.sort(returns[('Close', 'WEGE3.SA')].dropna())

# Obtendo quantis teóricos da distribuição normal
quantis_teoricos = stats.norm.ppf((np.arange(1, len(dados_ordenados) + 1) - 0.5) / len(dados_ordenados))

# Calculando a correlação de Pearson entre os quantis observados e os teóricos
correlacao, _ = stats.pearsonr(dados_ordenados, quantis_teoricos)

print(f"Correlação dos quantis para a ação: {correlacao:.4f}")









"""### TESTES NÃO PARAMÉTRICOS

### Teste de Mann-Whitney U

O **teste de Mann-Whitney U** é um **teste estatístico não paramétrico** usado para comparar duas amostras independentes e determinar se uma delas tende a ter valores maiores que a outra. Ele é uma alternativa ao teste t de Student quando os dados **não seguem uma distribuição normal**.

### Quando usar o teste de Mann-Whitney U?
- Quando se deseja comparar **duas amostras independentes**.
- Quando os dados **não são normalmente distribuídos**.
- Quando a variável de interesse é **ordinal** ou **contínua**.
- Quando a amostra tem um **tamanho pequeno** e o teste t não é adequado.

### Como funciona?
1. **Ordenação dos dados** → Os valores das duas amostras são combinados e organizados em ordem crescente.
2. **Cálculo dos postos (ranks)** → Cada valor recebe uma posição (ranking) baseada em sua magnitude.
3. **Soma dos postos** → A soma dos ranks é calculada para cada grupo.
4. **Cálculo da estatística U** → Baseado nos ranks, a estatística U é calculada para avaliar se há uma diferença significativa entre os grupos.
5. **Interpretação do valor-p** → Se o **valor-p** for menor que um nível de significância (ex.: 0.05), rejeitamos a hipótese nula e concluímos que há uma diferença significativa entre os grupos.

### Interpretação dos resultados:
- **Hipótese nula** (\(H_0\)) → As distribuições das duas amostras são iguais.
- **Hipótese alternativa** (\(H_A\)) → As distribuições são diferentes.
- Se **\( p < 0.05 \)** → Há **evidência estatística** de que os grupos possuem distribuições distintas.
- Se **\( p >= 0.05 \)** → **Não há evidências suficientes** para afirmar que há uma diferença entre as amostras.
"""

not_gaussian_assets_df

gaussian_assets_df

import itertools

all_tickers = [col[1] for col in returns.columns if col[0] == 'Close']
print(f"\nTickers encontrados: {all_tickers}")

# --- 3. Definir o nível de significância (alpha) ---
alpha = 0.05

# --- 4. Inicializar uma lista para armazenar os resultados dos pares com distribuição diferente ---
different_distribution_results = []

# --- 5. Iterar sobre todas as combinações únicas de tickers ---
# itertools.combinations(iterable, r) retorna r-length subsequences of elements from the input iterable.
# Aqui, r=2 para pares.
for ticker1, ticker2 in itertools.combinations(all_tickers, 2):
    # Acessar os dados de retorno para cada ticker, removendo NaNs
    # Usamos .loc para garantir o acesso correto ao MultiIndex
    sample1 = returns.loc[:, ('Close', ticker1)].dropna()
    sample2 = returns.loc[:, ('Close', ticker2)].dropna()

    # Verificar se as amostras têm dados suficientes após remover NaNs
    # Para o teste Mann-Whitney U, precisamos de pelo menos 2 observações em cada amostra
    if len(sample1) >= 2 and len(sample2) >= 2:
        # Realizar o teste de Mann-Whitney U
        stat, p = mannwhitneyu(sample1, sample2)

        # Interpretar o resultado
        if p <= alpha:
            conclusion = 'Diferente distribuição (rejeitar H0)'
            # Adicionar o resultado à lista se a distribuição for diferente
            different_distribution_results.append({
                'Ticker1': ticker1,
                'Ticker2': ticker2,
                'Statistic': round(stat, 3),
                'P_Value': round(p, 3),
                'Conclusion': conclusion
            })
            print(f"Comparando {ticker1} vs {ticker2}: Statistics={stat:.3f}, p={p:.3f} -> {conclusion}")
        else:
            print(f"Comparando {ticker1} vs {ticker2}: Statistics={stat:.3f}, p={p:.3f} -> Mesma distribuição (falhar em rejeitar H0)")
    else:
        print(f"Pulando a comparação entre {ticker1} e {ticker2} devido a dados insuficientes após remover NaNs.")

# --- 6. Criar um novo DataFrame com os resultados ---
df_different_distributions = pd.DataFrame(different_distribution_results)

print("\n--- Pares de Tickers com Distribuições Diferentes (df_different_distributions) ---")
if not df_different_distributions.empty:
    print(df_different_distributions)
else:
    print("Nenhum par de tickers foi encontrado com distribuições estatisticamente diferentes ao nível de significância de alpha=0.05.")

df_different_distributions





all_tickers = [col[1] for col in returns.columns if col[0] == 'Close']
print(f"\nTickers encontrados: {all_tickers}")

# --- 3. Definir o nível de significância (alpha) ---
alpha = 0.05

# --- 4. Inicializar uma lista para armazenar os resultados dos pares com distribuição diferente ---
different_distribution_results = []

# --- 5. Iterar sobre todas as combinações únicas de tickers ---
for ticker1, ticker2 in itertools.combinations(all_tickers, 2):
    # Acessar os dados de retorno para cada ticker, removendo NaNs
    sample1 = returns.loc[:, ('Close', ticker1)].dropna()
    sample2 = returns.loc[:, ('Close', ticker2)].dropna()

    # Verificar se as amostras têm dados suficientes após remover NaNs
    # O Kruskal-Wallis H-test requer pelo menos 2 observações em cada amostra
    if len(sample1) >= 2 and len(sample2) >= 2:
        # Realizar o teste de Kruskal-Wallis H-test
        stat, p = kruskal(sample1, sample2) # <-- Usando kruskal agora

        # Interpretar o resultado
        if p <= alpha:
            conclusion = 'Diferente distribuição (rejeitar H0)'
            # Adicionar o resultado à lista se a distribuição for diferente
            different_distribution_results.append({
                'Ticker1': ticker1,
                'Ticker2': ticker2,
                'Statistic': round(stat, 3),
                'P_Value': round(p, 3),
                'Conclusion': conclusion
            })
            print(f"Comparando {ticker1} vs {ticker2} (Kruskal-Wallis): Statistics={stat:.3f}, p={p:.3f} -> {conclusion}")
        else:
            print(f"Comparando {ticker1} vs {ticker2} (Kruskal-Wallis): Statistics={stat:.3f}, p={p:.3f} -> Mesma distribuição (falhar em rejeitar H0)")
    else:
        print(f"Pulando a comparação entre {ticker1} e {ticker2} devido a dados insuficientes após remover NaNs.")

# --- 6. Criar um novo DataFrame com os resultados ---
df_different_distributions = pd.DataFrame(different_distribution_results)

print("\n--- Pares de Tickers com Distribuições Diferentes (Kruskal-Wallis) ---")
if not df_different_distributions.empty:
    print(df_different_distributions)
else:
    print("Nenhum par de tickers foi encontrado com distribuições estatisticamente diferentes ao nível de significância de alpha=0.05.")

df_different_distributions

"""### Teste de Friedman

O **teste de Friedman** é um **teste estatístico não paramétrico** usado para comparar **três ou mais grupos dependentes** e determinar se há diferenças significativas entre eles. Ele é uma alternativa ao **ANOVA de medidas repetidas** quando os dados não seguem uma distribuição normal.

### Quando usar o teste de Friedman?
- Quando há **três ou mais grupos dependentes** (ex.: medidas repetidas sobre os mesmos indivíduos).
- Quando os dados **não são normalmente distribuídos**.
- Quando se deseja verificar se um fator afeta os resultados ao longo do tempo ou em diferentes condições.

### Como funciona?
1. **Organização dos dados** → Os valores são agrupados por sujeito ou unidade experimental.
2. **Cálculo dos postos (ranks)** → Em cada grupo, os valores recebem ranks para eliminar a influência de escalas de medida.
3. **Cálculo da estatística de Friedman** → A soma dos ranks é utilizada para determinar se há diferença significativa.
4. **Interpretação do valor-p** → Se o **valor-p** for menor que 0.05, rejeitamos a hipótese nula e concluímos que há diferença estatística.

### Interpretação dos resultados:
- **Hipótese nula** (\(H_0\)) → Todos os grupos têm distribuições iguais.
- **Hipótese alternativa** (\(H_A\)) → Pelo menos um grupo tem uma distribuição diferente.
- Se **\( p < 0.05 \)** → Há **diferença estatística significativa** entre os grupos.
- Se **\( p \geq 0.05 \)** → **Não há evidências suficientes** para afirmar que os grupos são diferentes.
"""

# Friedman test
# As in the previous example, we may have more than two different
# samples and an interest in whether all samples have the same distribution or not.
# seed the random number generator
seed(1)
# We will use the randn() NumPy function to generate a sample of 100 Gaussian random numbers
#in each sample with a mean of 0 and a standard deviation of 1. Observations in the first sample are
#scaled to have a mean of 50 and a standard deviation of 5. Observations in the second sample are scaled to
#have a mean of 51 and a standard deviation of 5.
data1 = 5 * randn(100) + 50
data2 = 5 * randn(100) + 50
data3 = 5 * randn(100) + 52
# compare samples
stat, p = friedmanchisquare(data1, data2, data3)
print('Statistics=%.3f, p=%.3f' % (stat, p))
# interpret
alpha = 0.05
if p > alpha:
	print('Same distributions (fail to reject H0)')
else:
	print('Different distributions (reject H0)')

"""### Diferenças entre o Teste de Kruskal-Wallis e o Teste de Friedman

O **teste de Kruskal-Wallis** e o **teste de Friedman** são testes não paramétricos que avaliam diferenças entre grupos, mas eles são aplicados em cenários diferentes.

### **Teste de Kruskal-Wallis (H-test)**
- **Compara três ou mais grupos independentes**.
- Alternativa não paramétrica ao **ANOVA de um fator**.
- Usa postos (ranks) para avaliar diferenças entre os grupos sem assumir normalidade.
- Exemplo: comparar os retornos de **ações diferentes** para verificar se têm distribuições estatísticas distintas.

### **Teste de Friedman**
- **Compara três ou mais grupos dependentes** (medidas repetidas no mesmo grupo de indivíduos).
- Alternativa não paramétrica ao **ANOVA de medidas repetidas**.
- Usa postos (ranks) para avaliar se há variação ao longo do tempo ou entre diferentes condições.
- Exemplo: testar se os retornos da **mesma ação** mudam de forma estatisticamente significativa em diferentes períodos.

### **Resumo das diferenças:**
- **Kruskal-Wallis** → Dados **independentes**, compara grupos **diferentes**.
- **Friedman** → Dados **dependentes**, compara **as mesmas unidades** ao longo do tempo ou em diferentes condições.
"""







